{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Project Title:**  ***\" Customer Segmentation for Retail \"***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading important libraries.\n",
    "#For data manipulation and analysis.\n",
    "import pandas as pd\n",
    "#MinMaxScaler is used to normalize data.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#For data visualization.\n",
    "import matplotlib.pyplot as plt\n",
    "#for K-Means clustering algorithm.\n",
    "from sklearn.cluster import KMeans\n",
    "#For evaluating clustering performance.\n",
    "from sklearn.metrics import silhouette_score\n",
    "#For dimensionality reduction.\n",
    "from sklearn.decomposition import PCA\n",
    "#Importinf TNSE from sklearn.\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 01:** Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the customer segmentation dataset.\n",
    "data = pd.read_excel(\"customer_segmentation_dataset.xlsx\")\n",
    "#Converting InvoiceDate to datetime format.\n",
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])\n",
    "#Current date(you can replace this with today's date or the latest date in the dataset).\n",
    "current_date = pd.to_datetime('12/1/2010 8:26')\n",
    "#Calculating Recency (days since last purchase).\n",
    "recency_df = data.groupby('CustomerID')['InvoiceDate'].max()\n",
    "recency_df = (current_date - recency_df).dt.days\n",
    "#Calculating Frequency (count of invoices).\n",
    "frequency_df = data.groupby('CustomerID')['InvoiceNo'].nunique()\n",
    "#Calculating Monetary (total spending).\n",
    "data['TotalSpend'] = data['Quantity'] * data['UnitPrice']\n",
    "monetary_df = data.groupby('CustomerID')['TotalSpend'].sum()\n",
    "#Combining Recency, Frequency and Monetary into one DataFrame.\n",
    "rfm_df = pd.DataFrame({'Recency': recency_df,'Frequency': frequency_df,'Monetary': monetary_df})\n",
    "#Initializing MinMaxScaler.\n",
    "scaler = MinMaxScaler()\n",
    "#Applying Min-Max Scaling to the RFM features.\n",
    "rfm_scaled = pd.DataFrame(scaler.fit_transform(rfm_df), columns=rfm_df.columns)\n",
    "#Viewing the scaled data.\n",
    "print(rfm_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 02:** Apply Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA for dimensionality reduction.\n",
    "#Setting to 3 because the dataset has 3 features.\n",
    "pca = PCA(n_components=3)  \n",
    "rfm_scaled_reduced = pca.fit_transform(rfm_scaled)\n",
    "#Elbow Method to determine the optimal number of clusters.\n",
    "wcss = []\n",
    "sil_scores = []\n",
    "#Sampling a smaller portion of the dataset for silhouette score calculation.\n",
    "#Adjusting based on dataset size.\n",
    "sample_size = 1000  \n",
    "#Taking a subset of the reduced data.\n",
    "rfm_sample = rfm_scaled_reduced[:sample_size]  \n",
    "#Testing for a range of cluster numbers (from 2 to 10).\n",
    "for i in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "    # Fitting the model on the scaled RFM data (subset).\n",
    "    kmeans.fit(rfm_sample)  \n",
    "    wcss.append(kmeans.inertia_)\n",
    "    # Using multiple cores for silhouette score.\n",
    "    sil_scores.append(silhouette_score(rfm_sample, kmeans.labels_, n_jobs=-1)) \n",
    "#Plotting the Elbow Method for determining the optimal number of clusters.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(2, 11), wcss, marker='o', color='b')\n",
    "plt.title('Elbow Method for Optimal Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('WCSS')\n",
    "\n",
    "# Plotting the Silhouette Score for determining the optimal number of clusters.\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(2, 11), sil_scores, marker='o', color='g')\n",
    "plt.title('Silhouette Score for Optimal Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#Initializing DBSCAN with parameters like eps (maximum distance between two points) and min_samples (minimum points to form a cluster).\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "#Fitting DBSCAN on the scaled RFM data (or your dataset).\n",
    "dbscan_labels = dbscan.fit_predict(rfm_scaled)  \n",
    "#Visualizing the DBSCAN clusters.\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(rfm_scaled.iloc[:, 0], rfm_scaled.iloc[:, 1], c=dbscan_labels, cmap='viridis', marker='o')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.xlabel('Feature 1')  \n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "#Printing the number of clusters and noise points.\n",
    "print(f\"Number of clusters: {len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)}\")\n",
    "print(f\"Noise points: {list(dbscan_labels).count(-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 03:** Visualization and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming `rfm_scaled_reduced` is your original dataset or scaled dataset.\n",
    "#Applying PCA for dimensionality reduction.\n",
    "pca = PCA(n_components=3)  \n",
    "rfm_pca_reduced = pca.fit_transform(rfm_scaled_reduced)\n",
    "#Creating a DataFrame for PCA components with appropriate column names.\n",
    "rfm_pca_df = pd.DataFrame(rfm_pca_reduced, columns=['PC1', 'PC2', 'PC3'])\n",
    "#KMeans clustering.\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
    "kmeans_labels = kmeans.fit_predict(rfm_pca_df)\n",
    "#Dimensionality reduction using t-SNE for 2D visualization.\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "rfm_tsne_reduced = tsne.fit_transform(rfm_pca_df)\n",
    "#Plotting the 2D visualization of the clusters using t-SNE.\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(rfm_tsne_reduced[:, 0], rfm_tsne_reduced[:, 1], c=kmeans_labels, cmap='viridis', marker='o')\n",
    "plt.title('2D Visualization of Clusters using t-SNE')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n",
    "#For 3D visualization using PCA components.\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(rfm_pca_df['PC1'], rfm_pca_df['PC2'], rfm_pca_df['PC3'], c=kmeans_labels, cmap='viridis', marker='o')\n",
    "ax.set_title('3D Visualization of Clusters using PCA')\n",
    "ax.set_xlabel('PCA Component 1')\n",
    "ax.set_ylabel('PCA Component 2')\n",
    "ax.set_zlabel('PCA Component 3')\n",
    "plt.show()\n",
    "#Adding the cluster labels to the original data for analysis.\n",
    "rfm_pca_df['Cluster'] = kmeans_labels\n",
    "#Calculating the median for each PCA component across the entire dataset.\n",
    "median_pc1 = rfm_pca_df['PC1'].median()\n",
    "median_pc2 = rfm_pca_df['PC2'].median()\n",
    "median_pc3 = rfm_pca_df['PC3'].median()\n",
    "#Calculating the mean of each feature for each cluster to analyze the characteristics.\n",
    "cluster_means = rfm_pca_df.groupby('Cluster').mean()\n",
    "print(cluster_means)\n",
    "#Suggesting personalized marketing strategies based on cluster characteristics.\n",
    "for cluster_num in cluster_means.index:\n",
    "    cluster_data = cluster_means.loc[cluster_num]\n",
    "    print(f\"Cluster {cluster_num} Characteristics:\")\n",
    "    #Using the PCA components (PC1, PC2, PC3).\n",
    "    if cluster_data['PC1'] > median_pc1:\n",
    "        print(\"  - This group has a higher value for PC1, suggesting they may be more engaged with premium products.\")\n",
    "    if cluster_data['PC2'] > median_pc2:\n",
    "        print(\"  - This group is more responsive to offers or discounts.\")\n",
    "    if cluster_data['PC3'] > median_pc3:\n",
    "        print(\"  - This group might benefit from loyalty programs.\")\n",
    "    print(\"  - Suggested marketing strategy: targeted offers, loyalty rewards and premium product promotions.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
